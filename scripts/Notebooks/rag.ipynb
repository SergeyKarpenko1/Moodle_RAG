{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergey/Desktop/Moodle_RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langdetect import detect\n",
    "from mlx_lm import generate, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "CHUNKS_DIR = Path(os.environ[\"MOODLE_CHUNKS_DIR\"])\n",
    "PERSIST_DIR = os.environ[\"MOODLE_CHROMA_DB_DIR\"]\n",
    "COLLECTION_NAME = os.environ.get(\"MOODLE_COLLECTION_NAME\", \"moodle_docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели для получения эмбеддингов, маленькая и хорошо работает на CPU\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf_embeddings = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 9 files: 100%|██████████| 9/9 [00:00<00:00, 102300.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# LLM для ответа\n",
    "model, tokenizer = load(\"mlx-community/Qwen2.5-7B-Instruct-4bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: moodle_docs\n",
      "Documents in collection: 2697\n"
     ]
    }
   ],
   "source": [
    "# Подключиться к уже сохраненной базе\n",
    "vector_store = Chroma(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=hf_embeddings,\n",
    "    persist_directory=PERSIST_DIR,\n",
    ")\n",
    "\n",
    "print(\"Collection:\", COLLECTION_NAME)\n",
    "print(\"Documents in collection:\", vector_store._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# так как модель эмбеддингов работает только с английским переводим запрос на него если он на руссском\n",
    "\n",
    "\n",
    "def prepare_query(user_query: str):\n",
    "    text = (user_query or \"\").strip()\n",
    "    if not text:\n",
    "        return \"\", \"ru\"\n",
    "\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except Exception:\n",
    "        lang = \"ru\"\n",
    "\n",
    "    # Нормализация до ru/en\n",
    "    if lang not in (\"ru\", \"en\"):\n",
    "        lang = \"en\"  # или \"ru\", но тогда чаще будет русский ответ\n",
    "\n",
    "    if lang == \"ru\":\n",
    "        try:\n",
    "            query_en = GoogleTranslator(source=\"ru\", target=\"en\").translate(text)\n",
    "            if not query_en:\n",
    "                query_en = text\n",
    "        except Exception:\n",
    "            query_en = text\n",
    "    else:\n",
    "        query_en = text\n",
    "\n",
    "    return query_en, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем контекст из топ-5 наиболее релевантных документов, возвращаем его вместе с языком запроса и результатами поиска для дальнейшего использования в ответе модели\n",
    "# Технически можно подавать только doc.page_content, но качество и управляемость обычно хуже.\n",
    "\n",
    "\n",
    "def build_context(user_query: str, vector_store, k: int = 5):\n",
    "    query_en, user_lang = prepare_query(user_query)\n",
    "    results = vector_store.similarity_search_with_score(query_en, k=k)\n",
    "\n",
    "    context_blocks = []\n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        distance = float(score)  # чем меньше, тем релевантнее\n",
    "        context_blocks.append(\n",
    "            f\"[{i}]\\n\"\n",
    "            f\"doc_title: {doc.metadata.get('doc_title', 'unknown')}\\n\"\n",
    "            f\"distance: {distance:.4f}\\n\"\n",
    "            f\"source_links: {doc.metadata.get('source_links', [])}\\n\"\n",
    "            f\"youtube_links: {doc.metadata.get('youtube_links', [])}\\n\"\n",
    "            f\"text:\\n{doc.page_content}\"\n",
    "        )\n",
    "\n",
    "    context = \"\\n\\n---\\n\\n\".join(context_blocks)\n",
    "    return context, user_lang, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(user_query: str, context: str, user_lang: str, recent_history=None):\n",
    "    answer_lang = \"Russian\" if user_lang == \"ru\" else \"English\"\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    <ROLE_DEFINITION>\n",
    "    You are the official Moodle documentation assistant acting as a technical consultant.\n",
    "    </ROLE_DEFINITION>\n",
    "\n",
    "    <MAIN_TASK_GUIDELINES>\n",
    "    Your task is to provide precise, formal, and verifiable answers strictly based on the provided CONTEXT.\n",
    "    You must directly answer the user’s question without adding external knowledge.\n",
    "    If the answer is not present in the CONTEXT, respond exactly: \"Not found in the documentation\".\n",
    "    Do not make assumptions, interpretations, or extrapolations beyond the CONTEXT.\n",
    "    The response must be structured and concise.\n",
    "    </MAIN_TASK_GUIDELINES>\n",
    "\n",
    "    <IMPORTANT_LANGUAGE_GUIDELINES>\n",
    "    Determine the language of the user's query and use THAT SAME language for:\n",
    "    - all actions,\n",
    "    - all search formulations,\n",
    "    - the final answer,\n",
    "    - all textual fields and outputs.\n",
    "\n",
    "    Answer strictly in {answer_lang}.\n",
    "\n",
    "    If the query is in Russian — all fields and responses must be strictly in Russian.\n",
    "    If the query is in English — all fields and responses must be strictly in English.\n",
    "    </IMPORTANT_LANGUAGE_GUIDELINES>\n",
    "\n",
    "    <OUTPUT_FORMAT_REQUIREMENTS>\n",
    "    The ending section is mandatory and must always be included:\n",
    "\n",
    "    - source_links: [list of links from CONTEXT]\n",
    "    - youtube_links: [list of links from CONTEXT if available; if none — write \"none\"]\n",
    "    </OUTPUT_FORMAT_REQUIREMENTS>\n",
    "    \"\"\".strip()\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    if recent_history:\n",
    "        for m in recent_history:\n",
    "            messages.append({\"role\": m[\"role\"], \"content\": m[\"content\"]})\n",
    "\n",
    "    # Текущий вопрос + контекст\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"QUESTION:\\n{user_query}\\n\\n\"\n",
    "                f\"CONTEXT:\\n{context}\\n\\n\"\n",
    "                f\"IMPORTANT: Respond ONLY in {answer_lang}. \"\n",
    "                f\"If QUESTION is English -> English only. If Russian -> Russian only.\"\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    answer = generate(model, tokenizer, prompt=prompt, max_tokens=550)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Опционально: простая поддержка follow-up в retrieval\n",
    "\n",
    "\n",
    "def retrieval_query_with_context(query: str, chat_history: list):\n",
    "    q = query.strip()\n",
    "    if len(q.split()) <= 4:\n",
    "        prev_users = [m[\"content\"] for m in chat_history if m[\"role\"] == \"user\"]\n",
    "        if prev_users:\n",
    "            return prev_users[-1] + \"\\n\" + q\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начните общение с ИИ! Введите 'выход', чтобы завершить разговор.\n",
      "\n",
      "✅ Ответ AI:\n",
      "Чтобы создать новый курс в Moodle, выполните следующие шаги:\n",
      "\n",
      "1. Перейдите в раздел Site administration > Courses > Manage courses and categories.\n",
      "2. Нажмите на ссылку \"New course\" в категории, где вы хотите создать новый курс.\n",
      "3. Введите настройки курса, затем выберите \"Save and return\" для возврата к своей странице курса или \"Save and display\" для перехода к следующему экрану.\n",
      "4. На следующем экране, если вы выбрали \"Save and display\", назначьте студентов/преподавателей для курса.\n",
      "\n",
      "Источники:\n",
      "- [https://docs.moodle.org/403/en/Adding_a_new_course](https://docs.moodle.org/403/en/Adding_a_new_course)\n",
      "- [https://youtu.be/MzK2jb-9SwE](https://youtu.be/MzK2jb-9SwE)\n",
      "\n",
      "source_links: ['https://docs.moodle.org/403/en/Adding_a_new_course', 'https://youtu.be/MzK2jb-9SwE']\n",
      "youtube_links: ['https://youtu.be/MzK2jb-9SwE']\n",
      "\n",
      "✅ Ответ AI:\n",
      "Чтобы настроить систему оценок в Moodle, выполните следующие шаги:\n",
      "\n",
      "1. Перейдите в раздел **Grading actions** на странице задания.\n",
      "2. Выберите **Download grading worksheet** для скачивания файла оценок и комментариев.\n",
      "3. Откройте скачанный файл в программе для работы с таблицами, например, Excel.\n",
      "4. Введите оценки и комментарии для каждого студента.\n",
      "5. Сохраните изменения в файле.\n",
      "6. Вернитесь к странице задания в Moodle.\n",
      "7. Выберите **Upload grading worksheet** для загрузки изменений.\n",
      "8. Загрузите сохраненный файл оценок.\n",
      "9. Проверьте, что оценки и комментарии правильно загружены.\n",
      "10. Подтвердите загрузку.\n",
      "\n",
      "Источники:\n",
      "- [https://docs.moodle.org/403/en/Using_Assignment](https://docs.moodle.org/403/en/Using_Assignment)\n",
      "- [https://youtu.be/MzK2jb-9SwE](https://youtu.be/MzK2jb-9SwE)\n",
      "\n",
      "source_links: ['https://docs.moodle.org/403/en/Using_Assignment', 'https://youtu.be/MzK2jb-9SwE']\n",
      "youtube_links: ['https://youtu.be/MzK2jb-9SwE']\n"
     ]
    }
   ],
   "source": [
    "def continual_chat(k: int = 5, history_turns: int = 3):\n",
    "    print(\"Начните общение с ИИ! Введите 'выход', чтобы завершить разговор.\")\n",
    "    chat_history = []\n",
    "\n",
    "    while True:\n",
    "        query = input(\"ВЫ: \").strip()\n",
    "        if query.lower() == \"выход\":\n",
    "            break\n",
    "\n",
    "        recent_history = chat_history[-2 * history_turns :]\n",
    "\n",
    "        # retrieval с учетом контекста (без перефраза)\n",
    "        rq = retrieval_query_with_context(query, chat_history)\n",
    "        context, _, results = build_context(rq, vector_store, k=k)\n",
    "\n",
    "        # язык ответа по текущему вопросу пользователя\n",
    "        _, user_lang = prepare_query(query)\n",
    "\n",
    "        # генерация с историей\n",
    "        answer = generate_answer(query, context, user_lang, recent_history=recent_history)\n",
    "\n",
    "        print(\"\\n✅ Ответ AI:\")\n",
    "        print(answer)\n",
    "\n",
    "        chat_history.append({\"role\": \"user\", \"content\": query})\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    continual_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Максимально простой замер базовых метрик RAGа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>mrr@5</th>\n",
       "      <th>faithfulness_llm_judge</th>\n",
       "      <th>faithfulness_citations</th>\n",
       "      <th>exact_source_attribution_ok</th>\n",
       "      <th>answer_links</th>\n",
       "      <th>relevant_sources</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Как создать новый курс в Moodle?</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[By default a regular teacher can't add a new ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[https://docs.moodle.org/403/en/Adding_a_new_c...</td>\n",
       "      <td>[https://docs.moodle.org/403/en/Adding_a_new_c...</td>\n",
       "      <td>Чтобы создать новый курс в Moodle, выполните с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Как настроить систему оценок в Moodle?</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Click on the assignment name on the Moodle co...</td>\n",
       "      <td>False</td>\n",
       "      <td>[https://docs.moodle.org/403/en/Grading_quick_...</td>\n",
       "      <td>[https://docs.moodle.org/403/en/Using_Assignment]</td>\n",
       "      <td>Чтобы настроить систему оценок в Moodle, выпол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Как просмотреть журналы активности пользователей?</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[Administration &gt; Course administration &gt; Repo...</td>\n",
       "      <td>True</td>\n",
       "      <td>[https://docs.moodle.org/403/en/Activity_repor...</td>\n",
       "      <td>[https://docs.moodle.org/403/en/Activity_report]</td>\n",
       "      <td>Чтобы просмотреть журналы активности пользоват...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  hit@5  mrr@5  \\\n",
       "0                   Как создать новый курс в Moodle?      1    1.0   \n",
       "1             Как настроить систему оценок в Moodle?      1    1.0   \n",
       "2  Как просмотреть журналы активности пользователей?      1    1.0   \n",
       "\n",
       "   faithfulness_llm_judge                             faithfulness_citations  \\\n",
       "0                       1  [By default a regular teacher can't add a new ...   \n",
       "1                       1  [Click on the assignment name on the Moodle co...   \n",
       "2                       1  [Administration > Course administration > Repo...   \n",
       "\n",
       "   exact_source_attribution_ok  \\\n",
       "0                        False   \n",
       "1                        False   \n",
       "2                         True   \n",
       "\n",
       "                                        answer_links  \\\n",
       "0  [https://docs.moodle.org/403/en/Adding_a_new_c...   \n",
       "1  [https://docs.moodle.org/403/en/Grading_quick_...   \n",
       "2  [https://docs.moodle.org/403/en/Activity_repor...   \n",
       "\n",
       "                                    relevant_sources  \\\n",
       "0  [https://docs.moodle.org/403/en/Adding_a_new_c...   \n",
       "1  [https://docs.moodle.org/403/en/Using_Assignment]   \n",
       "2   [https://docs.moodle.org/403/en/Activity_report]   \n",
       "\n",
       "                                              answer  \n",
       "0  Чтобы создать новый курс в Moodle, выполните с...  \n",
       "1  Чтобы настроить систему оценок в Moodle, выпол...  \n",
       "2  Чтобы просмотреть журналы активности пользоват...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Максимально простой eval-блок:\n",
    "# retrieval: Hit@k + MRR\n",
    "# generation: LLM-as-judge faithfulness (с цитатами)\n",
    "# attribution: exact source attribution check\n",
    "\n",
    "# Небольшой eval-набор:\n",
    "eval_items = [\n",
    "    {\n",
    "        \"question\": \"Как создать новый курс в Moodle?\",\n",
    "        \"relevant_sources\": [\"https://docs.moodle.org/403/en/Adding_a_new_course\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Как настроить систему оценок в Moodle?\",\n",
    "        \"relevant_sources\": [\"https://docs.moodle.org/403/en/Using_Assignment\"],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Как просмотреть журналы активности пользователей?\",\n",
    "        \"relevant_sources\": [\"https://docs.moodle.org/403/en/Activity_report\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def _to_list(x):\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return [str(i).strip() for i in x if str(i).strip()]\n",
    "    s = str(x).strip()\n",
    "    return [s] if s else []\n",
    "\n",
    "\n",
    "def get_ranked_source_links(results):\n",
    "    # results: [(doc, score), ...] из similarity_search_with_score\n",
    "    ranked = []\n",
    "    for doc, _ in results:\n",
    "        ranked.append(_to_list(doc.metadata.get(\"source_links\", [])))\n",
    "    return ranked\n",
    "\n",
    "\n",
    "def retrieval_hit_mrr(results, relevant_sources, k=5):\n",
    "    ranked = get_ranked_source_links(results)[:k]\n",
    "    relevant = set(relevant_sources)\n",
    "\n",
    "    hit = 0\n",
    "    mrr = 0.0\n",
    "\n",
    "    for rank, links in enumerate(ranked, start=1):\n",
    "        if any(link in relevant for link in links):\n",
    "            hit = 1\n",
    "            mrr = 1.0 / rank\n",
    "            break\n",
    "\n",
    "    return hit, mrr\n",
    "\n",
    "\n",
    "def extract_urls(text):\n",
    "    return re.findall(r\"https?://[^\\s\\]\\),]+\", text or \"\")\n",
    "\n",
    "\n",
    "def source_attribution_check(answer, results):\n",
    "    answer_links = set(extract_urls(answer))\n",
    "    retrieved_links = set()\n",
    "    for links in get_ranked_source_links(results):\n",
    "        for l in links:\n",
    "            retrieved_links.add(l)\n",
    "\n",
    "    all_cited_from_retrieved = len(answer_links) > 0 and answer_links.issubset(retrieved_links)\n",
    "    return all_cited_from_retrieved, sorted(answer_links), sorted(retrieved_links)\n",
    "\n",
    "\n",
    "def llm_judge_faithfulness(question, context, answer):\n",
    "    judge_prompt = f\"\"\"\n",
    "You are a strict faithfulness judge.\n",
    "Task: check whether ANSWER is fully supported by CONTEXT only.\n",
    "\n",
    "Return EXACTLY in this format:\n",
    "FAITHFUL: yes/no\n",
    "CITATIONS:\n",
    "- \"short quote 1 from CONTEXT\"\n",
    "- \"short quote 2 from CONTEXT\"\n",
    "\n",
    "Rules:\n",
    "- If any claim in ANSWER is not in CONTEXT => FAITHFUL: no\n",
    "- Quotes must be verbatim from CONTEXT\n",
    "- Max 2 quotes\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\n",
    "ANSWER:\n",
    "{answer}\n",
    "\"\"\".strip()\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": judge_prompt}]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    judge_raw = generate(model, tokenizer, prompt=prompt, max_tokens=180)\n",
    "\n",
    "    faithful = 1 if \"FAITHFUL: yes\" in judge_raw else 0\n",
    "    citations = re.findall(r'-\\s*\"([^\"]+)\"', judge_raw)\n",
    "    return faithful, citations, judge_raw\n",
    "\n",
    "\n",
    "# 2) Запуск\n",
    "rows = []\n",
    "\n",
    "for item in eval_items:\n",
    "    q = item[\"question\"]\n",
    "    relevant = item[\"relevant_sources\"]\n",
    "\n",
    "    context, user_lang, results = build_context(q, vector_store, k=5)\n",
    "    answer = generate_answer(q, context, user_lang)\n",
    "\n",
    "    hit5, mrr5 = retrieval_hit_mrr(results, relevant, k=5)\n",
    "    faithful, judge_citations, judge_raw = llm_judge_faithfulness(q, context, answer)\n",
    "    exact_attr_ok, answer_links, retrieved_links = source_attribution_check(answer, results)\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"question\": q,\n",
    "            \"hit@5\": hit5,\n",
    "            \"mrr@5\": round(mrr5, 4),\n",
    "            \"faithfulness_llm_judge\": faithful,  # 1/0\n",
    "            \"faithfulness_citations\": judge_citations,\n",
    "            \"exact_source_attribution_ok\": exact_attr_ok,\n",
    "            \"answer_links\": answer_links,\n",
    "            \"relevant_sources\": relevant,\n",
    "            \"answer\": answer,\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_eval = pd.DataFrame(rows)\n",
    "df_eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Moodle_RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
